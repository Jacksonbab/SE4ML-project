{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yhb19\\.conda\\envs\\pikrex\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, cv2, csv\n",
    "# from DAVE2 import DAVE2Model\n",
    "# from DAVE2pytorch import DAVE2PytorchModel\n",
    "import kornia\n",
    "\n",
    "from PIL import Image\n",
    "import copy\n",
    "from scipy import stats\n",
    "import torch.utils.data as data\n",
    "from pathlib import Path\n",
    "import skimage.io as sio\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import random\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, PILToTensor, functional as transforms\n",
    "# from io import BytesIO\n",
    "# import skimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stripleftchars(s):\n",
    "    # print(f\"{s=}\")\n",
    "    for i in range(len(s)):\n",
    "        if s[i].isnumeric():\n",
    "            return s[i:]\n",
    "    return -1\n",
    "\n",
    "class DataSequence(data.Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        image_paths = []\n",
    "        for p in Path(root).iterdir():\n",
    "            if p.suffix.lower() in [\".jpg\", \".png\", \".jpeg\", \".bmp\"]:\n",
    "                image_paths.append(p)\n",
    "        image_paths.sort(key=lambda p: int(stripleftchars(p.stem)))\n",
    "        self.image_paths = image_paths\n",
    "        # print(f\"{self.image_paths=}\")\n",
    "        self.df = pd.read_csv(f\"{self.root}/data.csv\")\n",
    "        self.cache = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.cache:\n",
    "            return self.cache[idx]\n",
    "        img_name = self.image_paths[idx]\n",
    "        image = sio.imread(img_name)\n",
    "\n",
    "        df_index = self.df.index[self.df['filename'] == img_name.name]\n",
    "        y_thro = self.df.loc[df_index, 'throttle_input'].array[0]\n",
    "        y_steer = self.df.loc[df_index, 'steering_input'].array[0]\n",
    "        y = [y_steer, y_thro]\n",
    "        # torch.stack(y, dim=1)\n",
    "        y = torch.tensor(y_steer)\n",
    "\n",
    "        # plt.title(f\"steering_input={y_steer.array[0]}\")\n",
    "        # plt.imshow(image)\n",
    "        # plt.show()\n",
    "        # plt.pause(0.01)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image).float()\n",
    "        # print(f\"{img_name.name=} {y_steer=}\")\n",
    "        # print(f\"{image=}\")\n",
    "        # print(f\"{type(image)=}\")\n",
    "        # print(self.df)\n",
    "        # print(y_steer.array[0])\n",
    "\n",
    "        # sample = {\"image\": image, \"steering_input\": y_steer.array[0]}\n",
    "        sample = {\"image\": image, \"steering_input\": y}\n",
    "\n",
    "        self.cache[idx] = sample\n",
    "        return sample\n",
    "\n",
    "class MultiDirectoryDataSequence(data.Dataset):\n",
    "    def __init__(self, root, image_size=(100,100), transform=None, robustification=False, noise_level=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.size = 0\n",
    "        self.image_size = image_size\n",
    "        image_paths_hashmap = {}\n",
    "        all_image_paths = []\n",
    "        self.dfs_hashmap = {}\n",
    "        self.dirs = []\n",
    "        marker = \"_YES\"\n",
    "        for p in Path(root).iterdir():\n",
    "            if p.is_dir() and marker in str(p): #\"_NO\" not in str(p) and \"YQWHF3\" not in str(p):\n",
    "                self.dirs.append(\"{}/{}\".format(p.parent,p.stem.replace(marker, \"\")))\n",
    "                image_paths = []\n",
    "                try:\n",
    "                    self.dfs_hashmap[f\"{p}\"] = pd.read_csv(f\"{p}/data.csv\")\n",
    "                except FileNotFoundError as e:\n",
    "                    print(e, \"\\nNo data.csv in directory\")\n",
    "                    continue\n",
    "                for pp in Path(p).iterdir():\n",
    "                    if pp.suffix.lower() in [\".jpg\", \".png\", \".jpeg\", \".bmp\"] and \"collection_trajectory\" not in pp.name:\n",
    "                        image_paths.append(pp)\n",
    "                        all_image_paths.append(pp)\n",
    "                image_paths.sort(key=lambda p: int(stripleftchars(p.stem)))\n",
    "                image_paths_hashmap[p] = copy.deepcopy(image_paths)\n",
    "                self.size += len(image_paths)\n",
    "        print(\"Finished intaking image paths!\")\n",
    "        self.image_paths_hashmap = image_paths_hashmap\n",
    "        self.all_image_paths = all_image_paths\n",
    "        # self.df = pd.read_csv(f\"{self.root}/data.csv\")\n",
    "        self.cache = {}\n",
    "        self.robustification = robustification\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def get_total_samples(self):\n",
    "        return self.size\n",
    "\n",
    "    def get_directories(self):\n",
    "        return self.dirs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.cache:\n",
    "            if self.robustification:\n",
    "                sample = self.cache[idx]\n",
    "                y_steer = sample[\"steering_input\"]\n",
    "                image = copy.deepcopy(sample[\"image\"])\n",
    "                if random.random() > 0.5:\n",
    "                    # flip image\n",
    "                    image = torch.flip(image, (2,))\n",
    "                    y_steer = -sample[\"steering_input\"]\n",
    "                if random.random() > 0.5:\n",
    "                    # blur\n",
    "                    gauss = kornia.filters.GaussianBlur2d((3,3), (1.5, 1.5))\n",
    "                    image = gauss(image[None])[0]\n",
    "                image = torch.clamp(image + (torch.randn(*image.shape) / self.noise_level), 0, 1)\n",
    "                return {\"image\": image, \"steering_input\": y_steer, \"throttle_input\": sample[\"throttle_input\"], \"all\": torch.FloatTensor([y_steer, sample[\"throttle_input\"]])}\n",
    "            else:\n",
    "                return self.cache[idx]\n",
    "        img_name = self.all_image_paths[idx]\n",
    "        image = Image.open(img_name)\n",
    "        image = image.resize(self.image_size)\n",
    "        # image = cv2.imread(img_name.__str__())\n",
    "        # image = cv2.resize(image, self.image_size) / 255\n",
    "        # image = self.fisheye(image)\n",
    "        orig_image = self.transform(image)\n",
    "        pathobj = Path(img_name)\n",
    "        df = self.dfs_hashmap[f\"{pathobj.parent}\"]\n",
    "        df_index = df.index[df['filename'] == img_name.name]\n",
    "        orig_y_steer = df.loc[df_index, 'steering_input'].item()\n",
    "        y_throttle = df.loc[df_index, 'throttle_input'].item()\n",
    "        y_steer = copy.deepcopy(orig_y_steer)\n",
    "        if self.robustification:\n",
    "            image = copy.deepcopy(orig_image)\n",
    "            if random.random() > 0.5:\n",
    "                # flip image\n",
    "                image = torch.flip(image, (2,))\n",
    "                y_steer = -orig_y_steer\n",
    "            if random.random() > 0.5:\n",
    "                # blur\n",
    "                gauss = kornia.filters.GaussianBlur2d((5, 5), (5.5, 5.5))\n",
    "                image = gauss(image[None])[0]\n",
    "                # image = kornia.filters.blur_pool2d(image[None], 3)[0]\n",
    "                # image = kornia.filters.max_blur_pool2d(image[None], 3, ceil_mode=True)[0]\n",
    "                # image = kornia.filters.median_blur(image, (3, 3))\n",
    "                # image = kornia.filters.median_blur(image, (10, 10))\n",
    "                # image = kornia.filters.box_blur(image, (3, 3))\n",
    "                # image = kornia.filters.box_blur(image, (5, 5))\n",
    "                # image = kornia.resize(image, image.shape[2:])\n",
    "                # plt.imshow(image.permute(1,2,0))\n",
    "                # plt.pause(0.01)\n",
    "            image = torch.clamp(image + (torch.randn(*image.shape) / self.noise_level), 0, 1)\n",
    "\n",
    "        else:\n",
    "            t = Compose([ToTensor()])\n",
    "            image = t(image).float()\n",
    "            # image = torch.from_numpy(image).permute(2,0,1) / 127.5 - 1\n",
    "\n",
    "        # vvvvvv uncomment below for value-image debugging vvvvvv\n",
    "        # plt.title(f\"{img_name}\\nsteering_input={y_steer.array[0]}\", fontsize=7)\n",
    "        # plt.imshow(image)\n",
    "        # plt.show()\n",
    "        # plt.pause(0.01)\n",
    "\n",
    "        sample = {\"image\": image, \"steering_input\": torch.FloatTensor([y_steer]), \"throttle_input\": torch.FloatTensor([y_throttle]), \"all\": torch.FloatTensor([y_steer, y_throttle])}\n",
    "        orig_sample = {\"image\": orig_image, \"steering_input\": torch.FloatTensor([orig_y_steer]), \"throttle_input\": torch.FloatTensor([y_throttle]), \"all\": torch.FloatTensor([orig_y_steer, y_throttle])}\n",
    "        self.cache[idx] = orig_sample\n",
    "        return sample\n",
    "\n",
    "    def get_outputs_distribution(self):\n",
    "        all_outputs = np.array([])\n",
    "        for key in self.dfs_hashmap.keys():\n",
    "            df = self.dfs_hashmap[key]\n",
    "            arr = df['steering_input'].to_numpy()\n",
    "            # print(\"len(arr)=\", len(arr))\n",
    "            all_outputs = np.concatenate((all_outputs, arr), axis=0)\n",
    "            # print(f\"Retrieved dataframe {key=}\")\n",
    "        all_outputs = np.array(all_outputs)\n",
    "        moments = self.get_distribution_moments(all_outputs)\n",
    "        return moments\n",
    "\n",
    "    ##################################################\n",
    "    # ANALYSIS METHODS\n",
    "    ##################################################\n",
    "\n",
    "    # Moments are 1=mean 2=variance 3=skewness, 4=kurtosis\n",
    "    def get_distribution_moments(self, arr):\n",
    "        moments = {}\n",
    "        moments['shape'] = np.asarray(arr).shape\n",
    "        moments['mean'] = np.mean(arr)\n",
    "        moments['median'] = np.median(arr)\n",
    "        moments['var'] = np.var(arr)\n",
    "        moments['skew'] = stats.skew(arr)\n",
    "        moments['kurtosis'] = stats.kurtosis(arr)\n",
    "        moments['max'] = max(arr)\n",
    "        moments['min'] = min(arr)\n",
    "        return moments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pikrex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
